train_data: "cocoqa"
seed: 42
data_seed: 42
max_steps: 10
per_device_train_batch_size: 1
gradient_accumulation_steps: 8
dataloader_pin_memory: False
dataloader_num_workers: 0
max_grad_norm: 1.0
fp16_opt_level: "O1"
warmup_ratio: 0.1
learning_rate: 0.0001
lr_scheduler_type: "cosine"
weight_decay: 0.01
logging_steps: 5
evaluation_strategy: "steps"
eval_steps: 0.125
save_strategy: "steps"
save_steps: 0.125
save_total_limit: 8
optim: "adamw_torch"
bf16: false
output_dir: "./model/freeze_llm_vlm_cocoqa"
overwrite_output_dir: False
report_to: "swanlab"
run_name: "freeze_llm_vlm_cocoqa"
remove_unused_columns: False
gradient_checkpointing: False
